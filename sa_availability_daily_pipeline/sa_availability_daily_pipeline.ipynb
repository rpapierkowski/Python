{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector  as connection\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir = 'G:/Data Marts/sa_avaiblaility_daily/Files/'\n",
    "scripts_dir = 'G:/Data Marts/sa_avaiblaility_daily/Scripts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\2370620089.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sa_list = pd.read_sql(sql_query,db_connections)\n"
     ]
    }
   ],
   "source": [
    "# Putty must be running while running the script\n",
    "with open(files_dir + 'db_credentials.txt', 'r') as f:\n",
    "    db_credentials = f.read().splitlines()\n",
    "\n",
    "try:\n",
    "    db_connections = connection.connect(\n",
    "        host=db_credentials[0],\n",
    "        user=db_credentials[1],\n",
    "        password=db_credentials[2],\n",
    "        database=db_credentials[3]\n",
    "    )\n",
    "    sql_file = open(scripts_dir + 'stating_sa_list.sql')\n",
    "    sql_query = sql_file.read()\n",
    "    sa_list = pd.read_sql(sql_query,db_connections)\n",
    "\n",
    "    # Close the connection\n",
    "    db_connections.close()  \n",
    "except Exception as e:\n",
    "    db_connections.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "salist_ids = ','.join(map(str, sa_list['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-22 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-23 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-24 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-25 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  total_log_id = pd.read_sql(total_log,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:121: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(sql_main_query,db_connections)\n",
      "C:\\Users\\rdpadmin\\AppData\\Local\\Temp\\ipykernel_13324\\1863368853.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check = pd.read_sql(sql_check_query,db_connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-27 is done\n",
      "Script is fully processed\n"
     ]
    }
   ],
   "source": [
    "# Read the last_updated_date to fetch last updated date\n",
    "last_updated_date_file = pd.read_csv(files_dir + 'last_updated_date.csv')\n",
    "\n",
    "# Set it as date to sql be able to read it\n",
    "last_updated_date_file['Date'] = pd.to_datetime(last_updated_date_file['Date']).dt.date\n",
    "\n",
    "# Separate the value\n",
    "last_updated_date = last_updated_date_file.iloc[0]['Date']\n",
    "\n",
    "# Set end date\n",
    "end_date = (last_updated_date+ pd.DateOffset(days=7)).date() \n",
    "\n",
    "# Set period you want to process\n",
    "tday = datetime.date.today() \n",
    "\n",
    "\n",
    "while last_updated_date < end_date: \n",
    "\n",
    "    if last_updated_date >= tday:\n",
    "        break\n",
    "\n",
    "    # Add 1 day to previously updated\n",
    "    last_updated_date = (last_updated_date+ pd.DateOffset(days=1)).date() \n",
    "\n",
    "    # Run MySQL query to fetch data\n",
    "    # Putty must be running while running the script\n",
    "    with open(files_dir + 'db_credentials.txt', 'r') as f:\n",
    "        db_credentials = f.read().splitlines()\n",
    "\n",
    "    try:\n",
    "        db_connections = connection.connect(\n",
    "            host=db_credentials[0],\n",
    "            user=db_credentials[1],\n",
    "            password=db_credentials[2],\n",
    "            database=db_credentials[3]\n",
    "        )\n",
    "\n",
    "        # Find total_log_id matching date\n",
    "        total_log_date = (last_updated_date+ pd.DateOffset(days=1)).date() \n",
    "        total_log = \"\"\"\n",
    "            SELECT total_log_id\n",
    "            FROM total_log_id \n",
    "            WHERE Updated = '{0}'\n",
    "        \"\"\".format(last_updated_date)\n",
    "\n",
    "        total_log_id = pd.read_sql(total_log,db_connections)\n",
    "        \n",
    "        # data fetching query\n",
    "        sql_main_query = \"\"\"\n",
    "            SELECT c.date\n",
    "            ,\t(\n",
    "                SELECT updated\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id  \n",
    "                AND tl.field_name_id = 5926\n",
    "                AND tl.ID < {2}\n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) minava_updated\n",
    "            ,\tsa.id AS sa_id  \n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 36\n",
    "                AND tl.ID < {2}\n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_inactive\n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 5926\n",
    "                AND tl.ID < {2}               \n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_minava\n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 747\n",
    "                AND tl.ID < {2}               \n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_old\n",
    "            ,\tIFNULL(sa.master_sa, sa.id) master_sa\n",
    "                \n",
    "            FROM calendar c\n",
    "\n",
    "            CROSS JOIN (SELECT sa.id, master_sa, sa.old\n",
    "            FROM saved_auctions sa\n",
    "            WHERE sa.id IN ({1})\n",
    "            ) sa\n",
    "\n",
    "            WHERE c.date = '{0}'\n",
    "                AND IF(sa.old = 1\n",
    "                ,\t{2}  < (\n",
    "                    SELECT tl.ID \n",
    "                    FROM total_log tl \n",
    "                    WHERE tl.table_name_id = 495 \n",
    "                    AND tl.tableid = sa.id \n",
    "                    AND tl.field_name_id = 747\n",
    "                    AND New_value = 1\n",
    "                    ORDER BY tl.ID DESC\n",
    "                    LIMIT 1)\n",
    "                ,\tsa.old = 0\n",
    "                    ) \n",
    "            GROUP BY c.date, sa.id\n",
    "\n",
    "            ORDER BY c.date\n",
    "            ;\n",
    "            \"\"\".format(last_updated_date, salist_ids, total_log_id.iloc[0, 0])\n",
    "        \n",
    "        # Fill variable with the fetched batch \n",
    "        result = pd.read_sql(sql_main_query,db_connections)\n",
    "\n",
    "        # Fetch the number of rows which suppose to be fetched\n",
    "        sql_check_query= \"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM(\n",
    "              SELECT c.date\n",
    "            ,\t(\n",
    "                SELECT updated\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id  \n",
    "                AND tl.field_name_id = 5926\n",
    "                AND tl.ID < {2}\n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) minava_updated\n",
    "            ,\tsa.id AS sa_id  \n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 36\n",
    "                AND tl.ID < {2}\n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_inactive\n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 5926\n",
    "                AND tl.ID < {2}               \n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_minava\n",
    "            ,\t(\n",
    "                SELECT new_value\n",
    "                FROM total_log tl \n",
    "                WHERE tl.table_name_id = 495 \n",
    "                AND tl.tableid = sa.id \n",
    "                AND tl.field_name_id = 747\n",
    "                AND tl.ID < {2}               \n",
    "                ORDER BY tl.ID DESC\n",
    "                LIMIT 1\n",
    "                ) sa_old\n",
    "            ,\tIFNULL(sa.master_sa, sa.id) master_sa\n",
    "                \n",
    "            FROM calendar c\n",
    "\n",
    "            CROSS JOIN (SELECT sa.id, master_sa, sa.old\n",
    "            FROM saved_auctions sa\n",
    "            WHERE sa.id IN ({1})\n",
    "            ) sa\n",
    "\n",
    "            WHERE c.date = '{0}'\n",
    "                AND IF(sa.old = 1\n",
    "                ,\t{2}  < (\n",
    "                    SELECT tl.ID \n",
    "                    FROM total_log tl \n",
    "                    WHERE tl.table_name_id = 495 \n",
    "                    AND tl.tableid = sa.id \n",
    "                    AND tl.field_name_id = 747\n",
    "                    AND New_value = 1\n",
    "                    ORDER BY tl.ID DESC\n",
    "                    LIMIT 1)\n",
    "                ,\tsa.old = 0\n",
    "                    ) \n",
    "            GROUP BY c.date, sa.id\n",
    "\n",
    "            ORDER BY c.date\n",
    "            ) che\n",
    "            ;\n",
    "            \"\"\".format(last_updated_date, salist_ids, total_log_id.iloc[0, 0])\n",
    "        \n",
    "        # Fill variable with the number of rows which suppose to be fetched\n",
    "        check = pd.read_sql(sql_check_query,db_connections)\n",
    "\n",
    "        # Check both values, it doesn't match break the script and do not update the file\n",
    "        if len(result) != check.iloc[0, 0]:\n",
    "            db_connections.close()  \n",
    "            print('Script has been terminated because values for ' + str(last_updated_date) + ' do not match')\n",
    "            break\n",
    "        \n",
    "        result_to_save = result.copy()\n",
    "        result_to_save.dropna(subset=['sa_minava'], inplace=True)    \n",
    "\n",
    "\n",
    "        # If it's all good, write the result into the file\n",
    "        with open(files_dir + 'final_result.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if csvfile.tell() == 0:  # Check if the file is empty\n",
    "                writer.writerow(result.columns)  # Write header row if file is empty\n",
    " \n",
    "            result_to_save.to_csv(csvfile, index=False, header=False)\n",
    "\n",
    "        # close the connection\n",
    "        db_connections.close()  \n",
    "    except Exception as e:\n",
    "        db_connections.close()\n",
    "        print(str(e))\n",
    "\n",
    "    # Check again to break the loop\n",
    "    if len(result) != check.iloc[0, 0]:\n",
    "        break\n",
    "    print(str(last_updated_date) + ' is done')\n",
    "\n",
    "    # Update previously updated\n",
    "    last_updated_date_file.loc[0, 'Date'] = last_updated_date\n",
    "    # Save new date into the file\n",
    "    last_updated_date_file.to_csv(files_dir + 'last_updated_date.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print('Script is fully processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
